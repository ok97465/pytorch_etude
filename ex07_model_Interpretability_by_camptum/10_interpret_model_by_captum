#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Model Interpretability by Captum

Created on Tue May 10 23:38:02 2022

@author: ok97465
"""
# %% Import
# Third party imports
import torch
from captum.attr import DeepLift, IntegratedGradients, Saliency
from matplotlib.axes import Axes
from matplotlib.figure import Figure
from matplotlib.pyplot import subplots
from numpy import float32, newaxis
from torch import Tensor, rand, where
from torch.nn import Module

# Local imports
from dataloader.mnist_dataloader import MnistData
from ex03_cnn_model_mnist.cnn_model_mnist import MnistCnnModel

# %% Parameters
path_data = "./data"
path_model_ckpt = (
    "./logs/cnn_model_mnist/230513_093434_ver0.001/checkpoint/"
    "epoch=24-valid_acc=0.99.ckpt"
)  # model trained in ex03
n_img_sample = 10000

# %% Data Load
device = torch.device("mps" if torch.backends.mps.is_available() else "gpu")
data_loader = MnistData(n_img_sample)
data_loader.setup()

data_sample, targets_sample = next(iter(data_loader.test_dataloader()))
data_sample = data_sample.to(device)
targets_sample = targets_sample.to(device)

# %% Load Model
model = MnistCnnModel().load_from_checkpoint(path_model_ckpt)
model.eval()


# %% Plot function
def plot_interpretation(
    model: Module, data: Tensor, idx_output: int
) -> tuple[Figure, list[Axes]]:
    """Plot interpretability."""
    fig, axes = subplots(1, 4, sharey=True, figsize=(11, 4))
    axes = axes.ravel()

    def draw(_d: Tensor, ax: Axes, title: str, cmap="viridis", vmin=0.0, vmax=1.0):
        """."""
        ax.imshow(_d[0][0].cpu(), cmap=cmap, vmin=vmin, vmax=vmax)
        ax.grid(False)
        ax.set_title(title)
        ax.set_xticks([])
        ax.set_yticks([])

    draw(data / data.max(), axes[0], "input")

    # Plot Saliency
    sl = Saliency(model)
    sl_attr = sl.attribute(data, target=idx_output)
    draw(sl_attr / sl_attr.max(), axes[1], "Saliency")

    # Plot IntegratedGradients
    ig = IntegratedGradients(model)
    ig_attr = ig.attribute(data, target=idx_output)
    draw(ig_attr, axes[2], "Integrated\nGradients", vmin=0.0, vmax=0.3)

    # Plot Deeplift
    dl = DeepLift(model)
    dl_attr = dl.attribute(data, target=idx_output)
    draw(dl_attr.cpu().detach().numpy(), axes[3], "DeepLift", vmin=0.0, vmax=0.2)

    return fig, axes


# %% Plot Interpretation
idx_target = 6
idx_candidate = where(targets_sample == idx_target)[0][0].item()
noise = rand((1, 1, 28, 28)) * 0.7
noise = noise.to(device)
d_in = data_sample[idx_candidate][newaxis] + noise

for idx_output in [1, idx_target]:
    fig, _ = plot_interpretation(model, d_in, idx_output)
    fig.suptitle(
        f"Interpretation of model(input {idx_target}, output index {idx_output})"
    )
    fig.tight_layout()
